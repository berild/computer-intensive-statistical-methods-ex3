\section{}
\label{sec:p1}
<<echo=FALSE>>=
read_chunk("../code/problem1.R")
@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In this exercise we analyze the data in \texttt{data3A\$x}, which contains a sequence of length $T = 100$ of a non-Gaussian time-series, and compare two different parameter estimators. We consider an $AR(2)$ model which is specified by the relation
%
\begin{equation*}
    x_t = \beta_1 x_{t-1} + \beta_2 x_{t-2} + e_t \, ,
\end{equation*}
%
where $e_t$ are iid random variable with zero mean and constant variance.

The least sum of squared residuals (LS) and least sum of absolute residuals (LA) are obtained by minimizing the following loss functions with respect to $\beta$:
%
\begin{align*}
    Q_{LS}(\vect{x}) &= \sum_{t=3}^T (x_t - \beta_1 x_{t-1} \beta_2 x_{t-2})^2 \\
    Q_{LS}(\vect{x}) &= \sum_{t=3}^T |x_t - \beta_1 x_{t-1} \beta_2 x_{t-2}| \, .
\end{align*}
%
Let us denote the minimizers by $\hat{\vect{\beta}}_{LS}$ and $\hat{\vect{\beta}}_{LA}$ (calculated by \texttt{ARp.beta.est}). Further we define the estimated residuals to be $\hat{e}_t = x_t - \hat{\beta_1} x_{t-1} - \hat{\beta_2} x_{t-2}$ for $t = 3, \dots , T$, and let $\Bar{e}$ be the mean of these. Finally we define the centered residuals $\hat{\epsilon}_t = \hat{e}_t - \Bar{e}$. The centered residuals are obtained using \texttt{ARp.resid}.

<<echo=FALSE>>=
load("../data/p1.Rdata")
nice = function(x, n=4) format(round(x, n), nsmall=n)
@

\paragraph{1.} We use the residual resampling bootstrap method to evaluate the relative performance of the two parameter estimators. First we calculate $\hat{\vect{\beta}}_{LA} \approx $ (\Sexpr{nice(beta_la)}) and $\hat{\vect{\beta}}_{LS} \approx $ (\Sexpr{nice(beta_ls)}) from the provided data set. Next we simulate the time series $B=2000$ times for each estimator. This is done by randomly choosing to consecutive values $x_t$ and $x_{t+1}$ from the original time series as initial values ($x_1^*, x_2^*$) and then iteratively finding $x_t^*$, $t = 3, \dots, T$ using the parameter estimators and bootstrap samples of the centered residuals. The \texttt{ARp.filter} function is used to build the time series, and the rest is done as shown in the code below.

<<p1_prelim, eval=FALSE>>=
@
\vspace{-1em}
<<p11_sim, eval=FALSE>>=
@

The original time series and three simulated time series using each of the estimators are shown in \figref{fig:p1_time_series}. It is not possible to conclude anything about the quality of the estimators from the plot, but it doesn't give any indications that the estimators are not good.

\begin{figure}
    \centering
    \includegraphics{figures/p1_time_series.pdf}
    \caption{Original time series data and three realizations using parameters estimated by least sum of squared residuals (LS) and parameters estimated by least sum of absolute residuals (LA), and bootstrap samples of the centered residuals.}
    \label{fig:p1_time_series}
\end{figure}

Now we estimate LA parameters from each of the time series simulated using the LA estimator, and similarly for LS. We calculate the means $\Bar{\vect{\beta}}^*_{LA}$ and $\Bar{\vect{\beta}}^*_{LS}$ and variances of all these and estimated parameters. This gives biases $\Bar{\vect{\beta}}^*_{LA} - \hat{\vect{\beta}}_{LA} \approx $ (\Sexpr{nice(beta_hat_la_bias)}), $\Bar{\vect{\beta}}^*_{LS} - \hat{\vect{\beta}}_{LS} \approx $ (\Sexpr{nice(beta_hat_ls_bias)}), and variances (\Sexpr{nice(beta_hat_la_var, 5)}) for the LA estimator and (\Sexpr{nice(beta_hat_ls_var, 5)}) for the LS estimator. The biases and variances of the LS estimator are a little larger. However, they are also very small; the biases are $< 1.5\%$ and the variances $< 1\%$ of the original estimator values. Anyways, this is an indication that the LS estimator is not optimal (UMVUE) for this AR process, even though it is for Gaussian AR processes.

\paragraph{2.} Next we wish to compute 95\% prediction intervals for $x_{101}$ using both the LA and LS estimators. We predict $x_{101}$ using a randomly chosen residual for each of the parameter estimates. I.e. we get 2000 predictions for each of the methods. To get the prediction interval we take the 0.025 and 0.975 quantiles from the predictions.

The resulting intervals are (\Sexpr{nice(x101_pi_la)}) (LA) and (\Sexpr{nice(x101_pi_ls)}) (LS). They are shown in \figref{fig:p1_preds}. The intervals are so close that they are almost indistinguishable in the plot. This is not surprising, considering the estimated parameters from the methods are very similar, as discussed in 1.

\begin{figure}
    \centering
    \includegraphics{figures/p1_preds.pdf}
    \caption{Original time series data and prediction intervals of $x_{101}$ obtained using different LA and LS estimators bootstrap samples of residuals calculated with those estimators.}
    \label{fig:p1_preds}
\end{figure}
